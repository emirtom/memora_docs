# Simple Semantic Search Using Memora 
Have you ever searched for something online and received results that seemed to understand what you meant, even if you didn’t use the exact words? This is called semantic search, and it’s all about understanding the meaning behind words rather than just matching the exact text. In this blog, we’ll explore how to perform simple semantic search with Memora.

## What is Semantic Search
Traditional search engines work by finding exact matches for the words you type. If you search for “buy running shoes,” they might look for pages that contain those exact words. But what if someone wrote “purchase sneakers for jogging”? You might miss out on relevant results.

Semantic search goes beyond this. It tries to understand the intent and meaning behind your words, not just their literal form. It can identify that “buy” and “purchase” are similar, as are “running shoes” and “sneakers.” This is made possible using **vector embeddings** and **vector databases**.

## Traditional Databases and Memora
When performing semantic search, the choice of database makes a big difference:

- **Traditional Databases**: These databases, such as SQL-based ones, are designed to store structured data like numbers, text fields, or dates. They perform searches based on exact matches or basic filters. If you use a traditional database for search, it will look for the exact words or patterns you provide, which is great for simple lookups but not for understanding meaning.
- **Memora**: Memora is designed to store and manage high-dimensional vectors, which are numerical representations of text or data generated by AI models. When you search using Memora, it finds vectors that are closest in meaning to your query vector. Instead of looking for exact words, it looks for similar meanings. This capability is what allows semantic search to provide more relevant and intuitive results.

## Possible Usages of Semantic Search
Semantic search isn’t just for product searches. Its applications are wide-ranging. For example:


1. **Customer Support**: Semantic search can match users' questions with the most relevant help articles, even if they phrase their queries differently. This makes it easier for users to find solutions without needing to use specific keywords.
2. **Medical Research**: Researchers can utilize semantic search to find studies or documents related to specific symptoms or treatments, even when the terminology varies. This helps connect information that might otherwise be overlooked.
3. **Legal Document Retrieval**: In the legal field, semantic search can help find similar legal documents or cases, saving time and ensuring that relevant information is easily accessible.
4. **Academic Research**: Semantic search can assist academics in locating related research papers, regardless of the specific wording used in their queries, helping them discover insights that align with their focus.
5. **Social Media Trend Analysis**: By searching through social media posts based on meaning rather than exact phrases, semantic search can help identify trends, track public sentiment, or uncover topics of interest more effectively.

# Step by Step Guide to Simple Semantic Search in Memora
This guide will go step by step in doing a simple semantic search inside Memora. You can get Python SDK by using pip in command line:

```shell
$ pip install memorapy
```

### Create a Collection
Memora uses collections to store data. We will create a collection with an additional field for storing the sentences. We also need to add an index for the vector field as it can be seen. For more explanation and options in collection, you can check "API Ref".

```python
from memorapy import Memora
from memorapy.models import Collection, Schema, Field 

client = Memora((api_key="YOUR_API_KEY", project_id="YOUR_PROJECT_ID")

collection = Collection(
    collection_name="rag",
    dimension=512,
    schema=Schema(
        auto_id=False,
        fields=[
            Field(
                field_name="sentence",
                data_type="VarChar",
                element_type_params=ElementTypeParams(max_length=256),
            ),
            Field(
                field_name="vector",
                data_type="FloatVector",
                element_type_params=ElementTypeParams(dim=512),
            ),
            Field(field_name="id", data_type="Int64", is_primary=True),
        ],
    ),
    indexes=[
        Index(
            metric_type="COSINE",
            field_name="vector",
            index_name="vector_index",
            params=IndexConfig(index_type="IVF_FLAT", nlist=128),
        )
    ],
)

result = client.collections.create(collection=collection)

print(result)
```
    {'message': 'collection created'}

### Prepare the Data
We will use sentence_transformers library from [https://huggingface.co](HuggingFace) and get the [https://huggingface.co/jinaai/jina-embeddings-v2-small-en](Jina) AI Model for converting our sentences to vectors to store inside our collection.

You can get sentence_transformers library in a similar way by using pip.

```shell
$ pip install sentence_transformers
```

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer(
    "jinaai/jina-embeddings-v2-small-en", 
    trust_remote_code=True # trust_remote_code is needed to use the encode method
)
sentences = [
    "The Eiffel Tower is one of the most famous landmarks in Paris.",
    "The Great Wall of China is a marvel of ancient engineering.",
    "A hot cup of coffee can be the perfect way to start the day.",
    "Learning a new language can open doors to different cultures.",
    "The Amazon rainforest is home to a vast diversity of wildlife.",
    "Exercising regularly can improve your overall health and well-being.",
    "Space exploration has led to numerous technological advancements.",
    "The Mona Lisa is a renowned piece of art created by Leonardo da Vinci.",
    "Cooking with fresh ingredients enhances the flavor of any dish.",
    "Machine learning algorithms power many modern AI applications."
]

embeddings = model.encode(sentences) # encode converts each sentence to its vector embedding by using jina model

print(embeddings.shape)

```
    (10, 512)


You can add the sentences and their embeddings into the collection by using the Insert method.

```python
embeddings = embeddings.tolist() # we need to convert the ndarray to list as they are not JSON serializable
data = [
    {"id": i, "vector": embeddings[i], "sentence": sentences[i]}
    for i in range(len(sentences))
]

result = client.vectors.insert(collection_name="semantic_search", data=data)

print(result)
```
    {'data': {'insertCount': 10, 'insertIds': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}}

### Perform a Semantic Search
Now that your data is in the collection, you can perform a search. Memora will find vectors (product descriptions) that are closest to your query vector, returning the most relevant results.

We will use an example sentence and try to find the most similar sentence in the collection. First, we need to convert into its embedding and use Search method to get the desired result. You can try different sentences and see the results for yourself.

```python

query_sentence = "What is a famous historical structure in China?"

query_vector = model.encode([query_sentence])

result = client.vectors.search(
    collection_name="semantic_search",
    data=[
        query_vector.tolist()[0]
    ],  # similar reason as above, we need to convert it to list
    anns_field="vector",  # name of the vector field
    output_fields=["sentence"],  # fields that we want to get beside ID
    limit=1,  # number of top similar sentences to return
)


print(result)
```
    {'data': [{'distance': 0.84239346, 'id': 1, 'sentence': 'The Great Wall of China is a marvel of ancient engineering.'}]}


## Learn More
If you’re interested in diving deeper into semantic search and vector databases, here are a few topics you can explore:

- What is a vector database?
- Vector Embeddings and how they work
- RAG and its use cases
